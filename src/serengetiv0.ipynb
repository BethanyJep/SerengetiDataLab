{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"bf554346-d6e7-43e0-9eda-4ac18984906d","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Python interpreter will be restarted.\n","Collecting keras\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","Installing collected packages: keras\n","Successfully installed keras-2.11.0\n","Python interpreter will be restarted.\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Python interpreter will be restarted.\nCollecting keras\n  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\nInstalling collected packages: keras\nSuccessfully installed keras-2.11.0\nPython interpreter will be restarted.\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["pip install keras"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"0caa2200-7f82-4a14-acf7-b0bf263c418d","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Python interpreter will be restarted.\n","Collecting tensorflow\n","  Downloading tensorflow-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n","Collecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","Collecting termcolor>=1.1.0\n","  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (58.0.4)\n","Requirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (21.0)\n","Collecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n","Collecting astunparse>=1.6.0\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting grpcio<2.0,>=1.24.3\n","  Downloading grpcio-1.51.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","Requirement already satisfied: keras<2.12,>=2.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9d7c8f72-b051-4248-b859-117ca745b1ce/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n","Collecting google-pasta>=0.1.1\n","  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Collecting opt-einsum>=2.3.2\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Requirement already satisfied: six>=1.12.0 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","Collecting libclang>=13.0.0\n","  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n","Collecting absl-py>=1.0.0\n","  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n","Collecting wrapt>=1.11.0\n","  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n","Collecting protobuf<3.20,>=3.9.2\n","  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","Requirement already satisfied: numpy>=1.20 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (1.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n","Collecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting h5py>=2.9.0\n","  Downloading h5py-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /databricks/python3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n","Collecting markdown>=2.6.8\n","  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Collecting tensorboard-plugin-wit>=1.6.0\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","Collecting werkzeug>=1.0.1\n","  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n","Requirement already satisfied: requests<3,>=2.21.0 in /databricks/python3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.26.0)\n","Collecting google-auth<3,>=1.6.3\n","  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n","Collecting cachetools<6.0,>=2.0.0\n","  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n","Collecting rsa<5,>=3.1.4\n","  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n","Collecting pyasn1-modules>=0.2.1\n","  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n","Collecting requests-oauthlib>=0.7.0\n","  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n","Collecting importlib-metadata>=4.4\n","  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n","Collecting zipp>=0.5\n","  Downloading zipp-3.12.1-py3-none-any.whl (6.7 kB)\n","Collecting pyasn1<0.5.0,>=0.4.6\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2021.10.8)\n","Collecting oauthlib>=3.0.0\n","  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n","Collecting MarkupSafe>=2.1.1\n","  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Requirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n","Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, MarkupSafe, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n","  Attempting uninstall: MarkupSafe\n","    Found existing installation: MarkupSafe 2.0.1\n","    Not uninstalling markupsafe at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9d7c8f72-b051-4248-b859-117ca745b1ce\n","    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.21.5\n","    Not uninstalling protobuf at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9d7c8f72-b051-4248-b859-117ca745b1ce\n","    Can't uninstall 'protobuf'. No files were found to uninstall.\n","Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.8.0 importlib-metadata-6.0.0 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 termcolor-2.2.0 werkzeug-2.2.2 wrapt-1.14.1 zipp-3.12.1\n","Python interpreter will be restarted.\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Python interpreter will be restarted.\nCollecting tensorflow\n  Downloading tensorflow-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\nCollecting flatbuffers>=2.0\n  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\nCollecting tensorflow-estimator<2.12,>=2.11.0\n  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\nCollecting termcolor>=1.1.0\n  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (58.0.4)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (21.0)\nCollecting tensorboard<2.12,>=2.11\n  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\nCollecting astunparse>=1.6.0\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nCollecting grpcio<2.0,>=1.24.3\n  Downloading grpcio-1.51.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\nRequirement already satisfied: keras<2.12,>=2.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9d7c8f72-b051-4248-b859-117ca745b1ce/lib/python3.9/site-packages (from tensorflow) (2.11.0)\nCollecting google-pasta>=0.1.1\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\nCollecting opt-einsum>=2.3.2\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\nRequirement already satisfied: six>=1.12.0 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1\n  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\nCollecting libclang>=13.0.0\n  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\nCollecting absl-py>=1.0.0\n  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\nCollecting wrapt>=1.11.0\n  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\nCollecting protobuf<3.20,>=3.9.2\n  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nRequirement already satisfied: numpy>=1.20 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (1.20.3)\nRequirement already satisfied: typing-extensions>=3.6.6 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\nCollecting gast<=0.4.0,>=0.2.1\n  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nCollecting h5py>=2.9.0\n  Downloading h5py-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /databricks/python3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\nCollecting markdown>=2.6.8\n  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\nCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\nCollecting werkzeug>=1.0.1\n  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\nRequirement already satisfied: requests<3,>=2.21.0 in /databricks/python3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.26.0)\nCollecting google-auth<3,>=1.6.3\n  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\nCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nCollecting importlib-metadata>=4.4\n  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.12.1-py3-none-any.whl (6.7 kB)\nCollecting pyasn1<0.5.0,>=0.4.6\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.2)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2021.10.8)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\nCollecting MarkupSafe>=2.1.1\n  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nRequirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\nInstalling collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, MarkupSafe, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9d7c8f72-b051-4248-b859-117ca745b1ce\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 4.21.5\n    Not uninstalling protobuf at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-9d7c8f72-b051-4248-b859-117ca745b1ce\n    Can't uninstall 'protobuf'. No files were found to uninstall.\nSuccessfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.8.0 importlib-metadata-6.0.0 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 termcolor-2.2.0 werkzeug-2.2.2 wrapt-1.14.1 zipp-3.12.1\nPython interpreter will be restarted.\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"8441a9da-085e-4fba-8570-8a93f0eebf6e","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Python interpreter will be restarted.\n","Collecting keras-applications\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","Requirement already satisfied: numpy>=1.9.1 in /databricks/python3/lib/python3.9/site-packages (from keras-applications) (1.20.3)\n","Requirement already satisfied: h5py in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9d7c8f72-b051-4248-b859-117ca745b1ce/lib/python3.9/site-packages (from keras-applications) (3.8.0)\n","Installing collected packages: keras-applications\n","Successfully installed keras-applications-1.0.8\n","Python interpreter will be restarted.\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Python interpreter will be restarted.\nCollecting keras-applications\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\nRequirement already satisfied: numpy>=1.9.1 in /databricks/python3/lib/python3.9/site-packages (from keras-applications) (1.20.3)\nRequirement already satisfied: h5py in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9d7c8f72-b051-4248-b859-117ca745b1ce/lib/python3.9/site-packages (from keras-applications) (3.8.0)\nInstalling collected packages: keras-applications\nSuccessfully installed keras-applications-1.0.8\nPython interpreter will be restarted.\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["pip install keras-applications"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f4886114-daa9-49e8-91f9-ee832d5c603b","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"Create Spark Dataframe\") \\\n","    .getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"329f6aee-35df-4e44-b814-7e9baeac3881","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["+--------------------+---------------+\n","|            image_id|           name|\n","+--------------------+---------------+\n","|S4/B06/B06_R2/S4_...|         impala|\n","|S3/S07/S07_R12/S3...|     wildebeest|\n","|S3/S07/S07_R12/S3...|     wildebeest|\n","|S3/U10/U10_R11/S3...|          zebra|\n","|S3/U10/U10_R11/S3...|     hartebeest|\n","|SER_S11/P13/P13_R...|        cheetah|\n","|SER_S11/J09/J09_R...|          zebra|\n","|S2/K03/K03_R2/S2_...|     wildebeest|\n","|S6/S13/S13_R2/S6_...|   hyenaspotted|\n","|S9/I02/I02_R2/S9_...|          zebra|\n","|S1/O05/O05_R1/S1_...|     guineafowl|\n","|S10/F06/F06_R1/S1...|     wildebeest|\n","|S1/Q11/Q11_R1/S1_...|gazellethomsons|\n","|S1/Q11/Q11_R1/S1_...|gazellethomsons|\n","|S8/H05/H05_R3/S8_...|     wildebeest|\n","|S1/R10/R10_R1/S1_...|  gazellegrants|\n","|S9/K06/K06_R2/S9_...|gazellethomsons|\n","|S3/E04/E04_R12/S3...|     wildebeest|\n","|S4/E04/E04_R2/S4_...|         impala|\n","|S4/E13/E13_R2/S4_...|     wildebeest|\n","+--------------------+---------------+\n","only showing top 20 rows\n","\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"+--------------------+---------------+\n|            image_id|           name|\n+--------------------+---------------+\n|S4/B06/B06_R2/S4_...|         impala|\n|S3/S07/S07_R12/S3...|     wildebeest|\n|S3/S07/S07_R12/S3...|     wildebeest|\n|S3/U10/U10_R11/S3...|          zebra|\n|S3/U10/U10_R11/S3...|     hartebeest|\n|SER_S11/P13/P13_R...|        cheetah|\n|SER_S11/J09/J09_R...|          zebra|\n|S2/K03/K03_R2/S2_...|     wildebeest|\n|S6/S13/S13_R2/S6_...|   hyenaspotted|\n|S9/I02/I02_R2/S9_...|          zebra|\n|S1/O05/O05_R1/S1_...|     guineafowl|\n|S10/F06/F06_R1/S1...|     wildebeest|\n|S1/Q11/Q11_R1/S1_...|gazellethomsons|\n|S1/Q11/Q11_R1/S1_...|gazellethomsons|\n|S8/H05/H05_R3/S8_...|     wildebeest|\n|S1/R10/R10_R1/S1_...|  gazellegrants|\n|S9/K06/K06_R2/S9_...|gazellethomsons|\n|S3/E04/E04_R12/S3...|     wildebeest|\n|S4/E04/E04_R2/S4_...|         impala|\n|S4/E13/E13_R2/S4_...|     wildebeest|\n+--------------------+---------------+\nonly showing top 20 rows\n\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["spark.conf.set(\"fs.azure.account.key.serengeti.blob.core.windows.net\", \"\")\n","\n","Database = \"dedicateddef\"\n","Server = \"serengetidatalab.sql.azuresynapse.net\"\n","User = \"user@serengetidatalab\"\n","# Pass = sqladmin00!\n","JdbcPort =  \"1433\"\n","Pass = \"\"\n","JdbcExtraOptions = \"encrypt=true;trustServerCertificate=true;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n","\n","sqlUrl = f\"jdbc:sqlserver://{Server}:{JdbcPort};database={Database};user={User};password={Pass};${JdbcExtraOptions}\"\n","\n","tableName = \"train\"\n","\n","tempDir = \"abfss://snapshot-serengeti@serengeti.dfs.core.windows.net/\"\n","\n","df_train = spark.read \\\n","  .format(\"jdbc\") \\\n","  .option(\"url\", sqlUrl) \\\n","  .option(\"tempDir\", tempDir) \\\n","  .option(\"forwardSparkAzureStorageCredentials\", \"true\") \\\n","  .option(\"dbTable\", tableName) \\\n","  .load()\n","\n","df_train.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d3c9a39f-9800-4e28-ab25-082060cdeae5","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["+--------------------+---------------+\n","|            image_id|           name|\n","+--------------------+---------------+\n","|S8/K09/K09_R2/S8_...|          zebra|\n","|S4/K11/K11_R2/S4_...|     wildebeest|\n","|S7/L05/L05_R2/S7_...|gazellethomsons|\n","|S4/M13/M13_R2/S4_...|gazellethomsons|\n","|S7/M05/M05_R3/S7_...|gazellethomsons|\n","|S7/M07/M07_R2/S7_...|      otherbird|\n","|SER_S11/H04/H04_R...|gazellethomsons|\n","|S5/I12/I12_R1/S5_...|       elephant|\n","|S2/D03/D03_R3/S2_...|     wildebeest|\n","|S2/D03/D03_R3/S2_...|          zebra|\n","|S5/U09/U09_R3/S5_...|   hyenaspotted|\n","|S3/P05/P05_R11/S3...|gazellethomsons|\n","|S2/E01/E01_R4/S2_...|          zebra|\n","|S2/E01/E01_R4/S2_...|          zebra|\n","|S9/I05/I05_R2/S9_...|     wildebeest|\n","|SER_S11/Q06/Q06_R...|          zebra|\n","|S9/J04/J04_R2/S9_...|     wildebeest|\n","|S9/J04/J04_R2/S9_...|          zebra|\n","|S9/J04/J04_R2/S9_...|     wildebeest|\n","|S2/H04/H04_R2/S2_...|          zebra|\n","+--------------------+---------------+\n","only showing top 20 rows\n","\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"+--------------------+---------------+\n|            image_id|           name|\n+--------------------+---------------+\n|S8/K09/K09_R2/S8_...|          zebra|\n|S4/K11/K11_R2/S4_...|     wildebeest|\n|S7/L05/L05_R2/S7_...|gazellethomsons|\n|S4/M13/M13_R2/S4_...|gazellethomsons|\n|S7/M05/M05_R3/S7_...|gazellethomsons|\n|S7/M07/M07_R2/S7_...|      otherbird|\n|SER_S11/H04/H04_R...|gazellethomsons|\n|S5/I12/I12_R1/S5_...|       elephant|\n|S2/D03/D03_R3/S2_...|     wildebeest|\n|S2/D03/D03_R3/S2_...|          zebra|\n|S5/U09/U09_R3/S5_...|   hyenaspotted|\n|S3/P05/P05_R11/S3...|gazellethomsons|\n|S2/E01/E01_R4/S2_...|          zebra|\n|S2/E01/E01_R4/S2_...|          zebra|\n|S9/I05/I05_R2/S9_...|     wildebeest|\n|SER_S11/Q06/Q06_R...|          zebra|\n|S9/J04/J04_R2/S9_...|     wildebeest|\n|S9/J04/J04_R2/S9_...|          zebra|\n|S9/J04/J04_R2/S9_...|     wildebeest|\n|S2/H04/H04_R2/S2_...|          zebra|\n+--------------------+---------------+\nonly showing top 20 rows\n\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["tableName2 = \"val\"\n","\n","df_val = spark.read \\\n","  .format(\"jdbc\") \\\n","  .option(\"url\", sqlUrl) \\\n","  .option(\"tempDir\", tempDir) \\\n","  .option(\"forwardSparkAzureStorageCredentials\", \"true\") \\\n","  .option(\"dbTable\", tableName2) \\\n","  .load()\n","\n","df_val.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"1529c83a-1aa9-4dff-93b4-5fb9e259eeee","showTitle":false,"title":""}},"outputs":[{"data":{"application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}","text/plain":[]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":{"application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}","text/plain":""},"datasetInfos":[],"metadata":{"kernelSessionId":"9a77f2d4-8c0bcdae3369eadfb0c13e60"},"removedWidgets":[],"type":"mimeBundle"}},"output_type":"display_data"}],"source":["import numpy as np\n","import keras\n","from keras.applications import ResNet50\n","from keras.preprocessing import image\n","#from keras.applications.resnet50 import preprocess_input\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras.optimizers import Adam\n","import pandas as pd \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c4c26de4-c584-4d60-bd96-6a4e5512088e","showTitle":false,"title":""}},"outputs":[],"source":["df_train = df_train.toPandas()\n","df_val = df_val.toPandas()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"788789eb-b2dd-401e-8fde-12e383ac1bc3","showTitle":false,"title":""}},"outputs":[],"source":["def imageURL(img_id):\n","    return f\"https://lilablobssc.blob.core.windows.net/snapshotserengeti-unzipped/{img_id}.JPG\"\n","\n","df_train[\"image_link\"] = df_train[\"image_id\"].apply(imageURL)\n","df_val[\"image_link\"] = df_val[\"image_id\"].apply(imageURL)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"12e01eb8-d059-4a91-99cc-d88cfe83edb1","showTitle":false,"title":""}},"outputs":[],"source":["import multiprocessing as mp\n","\n","def load_image(url, queue):\n","    try:\n","        response = requests.get(url)\n","        img = Image.open(BytesIO(response.content))\n","        img = img.resize((224, 224), Image.ANTIALIAS)\n","        image = np.array(img)\n","        queue.put(image)\n","    except:\n","        queue.put(None)\n","        \n","def load_images(image_urls):\n","    manager = mp.Manager()\n","    queue = manager.Queue()\n","    processes = []\n","    \n","    for url in image_urls:\n","        process = mp.Process(target=load_image, args=(url, queue))\n","        process.start()\n","        processes.append(process)\n","        \n","    images = []\n","    success_count = 0\n","    failure_count = 0\n","    \n","    for _ in range(len(image_urls)):\n","        image = queue.get()\n","        if image is not None:\n","            images.append(image)\n","            success_count += 1\n","        else:\n","            failure_count += 1\n","            \n","    for process in processes:\n","        process.join()\n","        \n","    train_data = np.stack(images)\n","    \n","    print(\"Successful loads:\", success_count)\n","    print(\"Failed loads:\", failure_count)\n","    \n","    return train_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e3ac8fb6-05dc-4ca5-b164-49624d65a01c","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Out[19]: 0    https://lilablobssc.blob.core.windows.net/snap...\n","1    https://lilablobssc.blob.core.windows.net/snap...\n","2    https://lilablobssc.blob.core.windows.net/snap...\n","3    https://lilablobssc.blob.core.windows.net/snap...\n","Name: image_link, dtype: object"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Out[19]: 0    https://lilablobssc.blob.core.windows.net/snap...\n1    https://lilablobssc.blob.core.windows.net/snap...\n2    https://lilablobssc.blob.core.windows.net/snap...\n3    https://lilablobssc.blob.core.windows.net/snap...\nName: image_link, dtype: object","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["sub_set = df_train.iloc[:4][\"image_link\"]\n","sub_set"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d822562d-8889-44c5-a4a9-61baa4be49e0","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n","\u001b[0;32m<command-3812778485697081>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# val_data = load_images(df_val.iloc[0][\"image_link\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;32m<command-3812778485697078>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(image_urls)\u001b[0m\n","\u001b[1;32m     36\u001b[0m         \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Successful loads:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\n","\u001b[0;32m/databricks/python/lib/python3.9/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n","\u001b[1;32m    421\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m    422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;31mValueError\u001b[0m: need at least one array to stack"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n\u001b[0;32m<command-3812778485697081>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# val_data = load_images(df_val.iloc[0][\"image_link\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m<command-3812778485697078>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(image_urls)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Successful loads:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n\n\u001b[0;32m/databricks/python/lib/python3.9/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;31mValueError\u001b[0m: need at least one array to stack","errorSummary":"<span class='ansi-red-fg'>ValueError</span>: need at least one array to stack","errorTraceType":"ansi","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["\n","train_data = load_images(sub_set)\n","# val_data = load_images(df_val.iloc[0][\"image_link\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"dfab9aec-3b28-4516-b2f1-07c39acfbe3f","showTitle":false,"title":""}},"outputs":[],"source":["labels_map = {\n","    'empty': 0,\n","    'human': 1,\n","    'gazellegrants': 2,\n","    'reedbuck': 3,\n","    'dikdik': 4,\n","    'zebra': 5,\n","    'porcupine': 6,\n","    'gazellethomsons': 7,\n","    'hyenaspotted': 8,\n","    'warthog': 9,\n","    'impala': 10,\n","    'elephant': 11,\n","    'aardvark': 12,\n","    'giraffe': 13,\n","    'mongoose': 14,\n","    'buffalo': 15,\n","    'hartebeest': 16,\n","    'guineafowl': 17,\n","    'wildebeest': 18,\n","    'leopard': 19,\n","    'ostrich': 20,\n","    'lionfemale': 21,\n","    'koribustard': 22,\n","    'otherbird': 23,\n","    'cheetah': 24,\n","    'honeybadger': 25,\n","    'bushbuck': 26,\n","    'jackal': 27,\n","    'aardwolf': 28,\n","    'hippopotamus': 29,\n","    'hyenastriped': 30,\n","    'hare': 31,\n","    'baboon': 32,\n","    'monkeyvervet': 33,\n","    'batearedfox': 34,\n","    'waterbuck': 35,\n","    'secretarybird': 36,\n","    'topi': 37,\n","    'serval': 38,\n","    'lionmale': 39,\n","    'eland': 40,\n","    'rodents': 41,\n","    'wildcat': 42,\n","    'civet': 43,\n","    'genet': 44,\n","    'zorilla': 45,\n","    'caracal': 46,\n","    'rhinoceros': 47,\n","    'reptiles': 48,\n","    'insectspider': 49,\n","    'duiker': 50,\n","    'cattle': 51,\n","    'vulture': 52,\n","    'steenbok': 53,\n","    'bat': 54,\n","    'fire': 55,\n","    'hyenabrown': 56,\n","    'wilddog': 57,\n","    'kudu': 58,\n","    'pangolin': 59,\n","    'lioncub': 60\n","}\n","\n","image_labels = ['empty', 'human', 'gazellegrants', 'reedbuck', 'dikdik', 'zebra', 'porcupine', 'gazellethomsons', 'hyenaspotted', 'warthog', 'impala', 'elephant', 'aardvark', 'giraffe', 'mongoose', 'buffalo', 'hartebeest', 'guineafowl', 'wildebeest', 'leopard', 'ostrich', 'lionfemale', 'koribustard', 'otherbird', 'cheetah', 'honeybadger', 'bushbuck', 'jackal', 'aardwolf', 'hippopotamus', 'hyenastriped', 'hare', 'baboon', 'monkeyvervet', 'batearedfox', 'waterbuck', 'secretarybird', 'topi', 'serval', 'lionmale', 'eland', 'rodents', 'wildcat', 'civet', 'genet', 'zorilla', 'caracal', 'rhinoceros', 'reptiles', 'insectspider', 'duiker', 'cattle', 'vulture', 'steenbok', 'bat', 'fire', 'hyenabrown', 'wilddog', 'kudu', 'pangolin', 'lioncub']\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"9aff0ad9-5cff-431c-b58a-a37b18fe8191","showTitle":false,"title":""}},"outputs":[],"source":["import numpy as np\n","\n","def one_hot_encode_labels(image_labels, labels_map):\n","    # Convert the label names to integers using the labels_map dictionary\n","    label_ints = [labels_map[label] for label in image_labels]\n","    # Perform one-hot encoding using np.eye\n","    train_labels = np.eye(len(labels_map))[label_ints]\n","    return train_labels\n","\n","train_labels = one_hot_encode_labels(image_labels, labels_map)\n"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"serengetiv0","notebookOrigID":3812778485697065,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
