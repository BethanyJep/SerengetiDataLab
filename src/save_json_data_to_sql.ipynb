{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#r \"nuget: Microsoft.Azure.Storage.Common\"\n",
        "#r \"nuget: Microsoft.Azure.Storage.Blob\"\n",
        "#r \"nuget: Microsoft.Azure.Storage.File\"\n",
        "#r \"nuget: Newtonsoft.Json\"\n",
        "#r \"nuget: System.Data.SqlClient\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 205,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:53.5254736Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:53.6571337Z",
              "execution_finish_time": "2023-01-31T13:03:53.819901Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 205, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 205,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "using Microsoft.Azure.Storage;\n",
        "using Microsoft.Azure.Storage.Blob;\n",
        "using System.IO;\n",
        "using Newtonsoft.Json;\n",
        "using System.Data.SqlClient;\n",
        "using System.Data;\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 206,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:53.5864962Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:53.9519006Z",
              "execution_finish_time": "2023-01-31T13:03:54.1269391Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 206, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 206,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "public class SerengetiData\n",
        "{\n",
        "    [JsonProperty(\"info\")]\n",
        "    public Info Info { get; set; }\n",
        "\n",
        "    [JsonProperty(\"categories\")]\n",
        "    public List<Category> Categories { get; set; }\n",
        "\n",
        "    [JsonProperty(\"images\")]\n",
        "    public List<Image> Images { get; set; }\n",
        "\n",
        "    [JsonProperty(\"annotations\")]\n",
        "    public List<Annotation> Annotations { get; set; }\n",
        "}\n",
        "\n",
        "public class Annotation\n",
        "{\n",
        "    [JsonProperty(\"sequence_level_annotation\")]\n",
        "    public bool SequenceLevelAnnotation { get; set; }\n",
        "\n",
        "    [JsonProperty(\"id\")]\n",
        "    public string Id { get; set; }\n",
        "\n",
        "    [JsonProperty(\"category_id\")]\n",
        "    public long CategoryId { get; set; }\n",
        "\n",
        "    [JsonProperty(\"seq_id\")]\n",
        "    public string SeqId { get; set; }\n",
        "\n",
        "    [JsonProperty(\"season\")]\n",
        "    public string Season { get; set; }\n",
        "\n",
        "    [JsonProperty(\"datetime\")]\n",
        "    public DateTimeOffset Datetime { get; set; }\n",
        "\n",
        "    [JsonProperty(\"subject_id\")]\n",
        "    public string SubjectId { get; set; }\n",
        "\n",
        "    [JsonProperty(\"count\")]\n",
        "    public object Count { get; set; }\n",
        "\n",
        "    [JsonProperty(\"standing\")]\n",
        "    public object Standing { get; set; }\n",
        "\n",
        "    [JsonProperty(\"resting\")]\n",
        "    public object Resting { get; set; }\n",
        "\n",
        "    [JsonProperty(\"moving\")]\n",
        "    public object Moving { get; set; }\n",
        "\n",
        "    [JsonProperty(\"interacting\")]\n",
        "    public object Interacting { get; set; }\n",
        "\n",
        "    [JsonProperty(\"young_present\")]\n",
        "    public object YoungPresent { get; set; }\n",
        "\n",
        "    [JsonProperty(\"image_id\")]\n",
        "    public string ImageId { get; set; }\n",
        "\n",
        "    [JsonProperty(\"location\")]\n",
        "    public string Location { get; set; }\n",
        "}\n",
        "\n",
        "public class Category\n",
        "{\n",
        "    [JsonProperty(\"id\")]\n",
        "    public long Id { get; set; }\n",
        "\n",
        "    [JsonProperty(\"name\")]\n",
        "    public string Name { get; set; }\n",
        "}\n",
        "\n",
        "public class Image\n",
        "{\n",
        "    [JsonProperty(\"id\")]\n",
        "    public string Id { get; set; }\n",
        "\n",
        "    [JsonProperty(\"file_name\")]\n",
        "    public string FileName { get; set; }\n",
        "\n",
        "    [JsonProperty(\"frame_num\")]\n",
        "    public long FrameNum { get; set; }\n",
        "\n",
        "    [JsonProperty(\"seq_id\")]\n",
        "    public string SeqId { get; set; }\n",
        "\n",
        "    [JsonProperty(\"width\")]\n",
        "    public long Width { get; set; }\n",
        "\n",
        "    [JsonProperty(\"height\")]\n",
        "    public long Height { get; set; }\n",
        "\n",
        "    [JsonProperty(\"corrupt\")]\n",
        "    public bool Corrupt { get; set; }\n",
        "\n",
        "    [JsonProperty(\"location\")]\n",
        "    public string Location { get; set; }\n",
        "\n",
        "    [JsonProperty(\"seq_num_frames\")]\n",
        "    public long SeqNumFrames { get; set; }\n",
        "\n",
        "    [JsonProperty(\"datetime\")]\n",
        "    public DateTimeOffset Datetime { get; set; }\n",
        "}\n",
        "\n",
        "public class Info\n",
        "{\n",
        "    [JsonProperty(\"version\")]\n",
        "    public string Version { get; set; }\n",
        "\n",
        "    [JsonProperty(\"description\")]\n",
        "    public string Description { get; set; }\n",
        "\n",
        "    [JsonProperty(\"date_created\")]\n",
        "    public long DateCreated { get; set; }\n",
        "\n",
        "    [JsonProperty(\"contributor\")]\n",
        "    public string Contributor { get; set; }\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 207,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:53.6347935Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:54.2425133Z",
              "execution_finish_time": "2023-01-31T13:03:54.3952431Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 207, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 207,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CloudBlobContainer blobContainer;\n",
        "CloudBlobDirectory blobDirectory;\n",
        "SqlConnection sqlConn;\n",
        "\n",
        "var dbConnectionString = \"\";\n",
        "var storageConnectionString = \"\";\n",
        "\n",
        "var sqlCon = new SqlConnection(dbConnectionString);\n",
        "\n",
        "sqlCon.OpenAsync();\n",
        "\n",
        "private void InitStorageAndDb()\n",
        "{\n",
        "    // Create a FileEndpoint for the destination ADLS\n",
        "    CloudStorageAccount storageAccount = CloudStorageAccount.Parse(storageConnectionString);\n",
        "\n",
        "    var blobClient= storageAccount.CreateCloudBlobClient();\n",
        "    blobContainer =  blobClient.GetContainerReference(\"snapshot-serengeti\");\n",
        "    blobDirectory = blobContainer.GetDirectoryReference(\"metadata\");\n",
        "    sqlConn = new SqlConnection(dbConnectionString);\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 208,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:53.7259251Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:54.5040377Z",
              "execution_finish_time": "2023-01-31T13:03:54.6750183Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 208, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 208,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "private async Task<T> ReadJsonFile<T> (CloudBlockBlob jsonBlob)\n",
        "{\n",
        "    using (var memoryStream = new MemoryStream())\n",
        "    {\n",
        "        // Download the JSON file to a memory stream\n",
        "        await jsonBlob.DownloadToStreamAsync(memoryStream);\n",
        "\n",
        "        // Reset the memory stream position\n",
        "        memoryStream.Position = 0;\n",
        "\n",
        "        // Use a JsonTextReader to read the JSON file in chunks\n",
        "        using (var jsonTextReader = new JsonTextReader(new StreamReader(memoryStream)) { CloseInput = false })\n",
        "        {\n",
        "            // Use a JsonSerializer to deserialize the JSON file\n",
        "            var jsonSerializer = new JsonSerializer();\n",
        "\n",
        "            // Read the JSON file in chunks and deserialize it\n",
        "            return jsonSerializer.Deserialize<T>(jsonTextReader);\n",
        "        }\n",
        "    }\n",
        "}\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 209,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:53.7839045Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:54.7782092Z",
              "execution_finish_time": "2023-01-31T13:03:54.9492879Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 209, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 209,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "private async Task CreateTablesAsync()\n",
        "{\n",
        "    var commands = new Dictionary<string, string>()\n",
        "    {\n",
        "        {\"images\", \"CREATE TABLE images (id VARCHAR(255), file_name VARCHAR(255), frame_num INT, seq_id VARCHAR(255), width INT, height INT, corrupt BIT, location VARCHAR(255), seq_num_frames INT, datetime DATETIME);\"},\n",
        "        {\"categories\", \"CREATE TABLE categories (id INT, name VARCHAR(255));\"},\n",
        "        {\"annotations\", \"CREATE TABLE annotations ( id VARCHAR(255) NOT NULL, category_id INT NOT NULL, seq_id VARCHAR(255) NOT NULL, season VARCHAR(255) NOT NULL, datetime DATETIME NOT NULL, image_id VARCHAR(255) NOT NULL, location VARCHAR(255) NOT NULL );\"},\n",
        "        {\"train\", \"CREATE TABLE train ( location VARCHAR(255));\"},\n",
        "        {\"val\", \"CREATE TABLE val ( location VARCHAR(255));\"}\n",
        "    };\n",
        "\n",
        "\n",
        "    await sqlConn.OpenAsync();\n",
        "\n",
        "    foreach(var command in commands)\n",
        "    {\n",
        "        using(SqlCommand sqlCmd =new SqlCommand(command.Value, sqlConn))\n",
        "        {\n",
        "            try\n",
        "            {\n",
        "                await sqlCmd.ExecuteNonQueryAsync();\n",
        "                Console.WriteLine($\"Table {command.Key} created successfully.\");\n",
        "            }\n",
        "            catch(Exception ex)\n",
        "            {\n",
        "                Console.WriteLine($\"Error creating table {command.Key}: \" + ex.Message);\n",
        "            }\n",
        "        }   \n",
        "    }\n",
        "\n",
        "    await sqlConn.CloseAsync();\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 210,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:53.8238907Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:55.0621194Z",
              "execution_finish_time": "2023-01-31T13:03:55.2242661Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 210, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 210,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "private async Task BulkInsertImages(List<Image> images)\n",
        "{\n",
        "    await sqlConn.OpenAsync();\n",
        "\n",
        "    using(var bulkCpy = new SqlBulkCopy(sqlConn))\n",
        "    {\n",
        "        bulkCpy.DestinationTableName=\"images\";\n",
        "\n",
        "        var dataTable = new DataTable();\n",
        "        dataTable.Columns.Add(\"id\", typeof(string));\n",
        "        dataTable.Columns.Add(\"file_name\", typeof(string));\n",
        "        dataTable.Columns.Add(\"frame_num\", typeof(long));\n",
        "        dataTable.Columns.Add(\"seq_id\", typeof(string));\n",
        "        dataTable.Columns.Add(\"width\", typeof(long));\n",
        "        dataTable.Columns.Add(\"height\", typeof(long));\n",
        "        dataTable.Columns.Add(\"corrupt\", typeof(bool));\n",
        "        dataTable.Columns.Add(\"location\", typeof(string));\n",
        "        dataTable.Columns.Add(\"seq_num_frames\", typeof(long));\n",
        "        dataTable.Columns.Add(\"datetime\", typeof(DateTime));\n",
        "\n",
        "        foreach (var image in images)\n",
        "        {\n",
        "            var row = dataTable.NewRow();\n",
        "            row[\"id\"] = image.Id;\n",
        "            row[\"file_name\"] = image.FileName;\n",
        "            row[\"frame_num\"] = image.FrameNum;\n",
        "            row[\"seq_id\"] = image.SeqId;\n",
        "            row[\"width\"] = image.Width;\n",
        "            row[\"height\"] = image.Height;\n",
        "            row[\"corrupt\"] = image.Corrupt;\n",
        "            row[\"location\"] = image.Location;\n",
        "            row[\"seq_num_frames\"] = image.SeqNumFrames;\n",
        "            row[\"datetime\"] = image.Datetime.DateTime;\n",
        "\n",
        "            dataTable.Rows.Add(row);\n",
        "        }\n",
        "\n",
        "        await Task.Run(() => bulkCpy.WriteToServer(dataTable));\n",
        "    }\n",
        "\n",
        "    await sqlConn.CloseAsync();\n",
        "}\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 211,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:53.8774696Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:55.35409Z",
              "execution_finish_time": "2023-01-31T13:03:55.5046691Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 211, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 211,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "private async Task BulkInsertCategories(List<Category> categories)\n",
        "{\n",
        "    await sqlConn.OpenAsync();\n",
        "\n",
        "    using (var bulkCpy = new SqlBulkCopy(sqlConn))\n",
        "    {\n",
        "        bulkCpy.DestinationTableName = \"categories\";\n",
        "\n",
        "        var dataTable = new DataTable();\n",
        "        dataTable.Columns.Add(\"id\", typeof(long));\n",
        "        dataTable.Columns.Add(\"name\", typeof(string));\n",
        "\n",
        "        foreach(var category in categories)\n",
        "        {\n",
        "            var row = dataTable.NewRow();\n",
        "            row[\"id\"] = category.Id;\n",
        "            row[\"name\"] = category.Name;\n",
        "        }\n",
        "\n",
        "        await Task.Run(() => bulkCpy.WriteToServer(dataTable));\n",
        "    }\n",
        "\n",
        "    await sqlConn.CloseAsync();\n",
        "}\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 212,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:53.9653001Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:55.6228013Z",
              "execution_finish_time": "2023-01-31T13:03:55.7870839Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 212, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 212,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "private async Task BulkInsertAnnotations(List<Annotation> annotations)\n",
        "{\n",
        "    await sqlConn.OpenAsync();\n",
        "\n",
        "    using (var bulkCpy = new SqlBulkCopy(sqlConn))\n",
        "    {\n",
        "        bulkCpy.DestinationTableName = \"annotations\";\n",
        "\n",
        "        var dataTable = new DataTable();\n",
        "        dataTable.Columns.Add(\"id\", typeof(string));\n",
        "        dataTable.Columns.Add(\"category_id\", typeof(long));\n",
        "        dataTable.Columns.Add(\"seq_id\", typeof(string));\n",
        "        dataTable.Columns.Add(\"season\", typeof(string));\n",
        "        dataTable.Columns.Add(\"datetime\", typeof(DateTime));\n",
        "        dataTable.Columns.Add(\"image_id\", typeof(string));\n",
        "        dataTable.Columns.Add(\"location\", typeof(string));\n",
        "\n",
        "        foreach (var annotation in annotations)\n",
        "        {\n",
        "            var row = dataTable.NewRow();\n",
        "            row[\"id\"] = annotation.Id;\n",
        "            row[\"category_id\"] = annotation.CategoryId;\n",
        "            row[\"seq_id\"] = annotation.SeqId;\n",
        "            row[\"season\"] = annotation.Season;\n",
        "            row[\"datetime\"] = annotation.Datetime.LocalDateTime;\n",
        "            row[\"image_id\"] = annotation.ImageId;\n",
        "            row[\"location\"] = annotation.Location;\n",
        "            dataTable.Rows.Add(row);\n",
        "        }\n",
        "\n",
        "        await bulkCpy.WriteToServerAsync(dataTable);\n",
        "    }\n",
        "    await sqlConn.CloseAsync();\n",
        "}\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 213,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:54.027748Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:55.9061063Z",
              "execution_finish_time": "2023-01-31T13:03:56.077263Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 213, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 213,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "private async Task BulkInsertSplits(dynamic splits)\n",
        "{\n",
        "    await sqlConn.OpenAsync();\n",
        "\n",
        "    using (var bulkCpy = new SqlBulkCopy(sqlConn))\n",
        "    {\n",
        "        bulkCpy.DestinationTableName = \"train\";\n",
        "\n",
        "        var dataTable = new DataTable();\n",
        "        dataTable.Columns.Add(\"location\", typeof(string));\n",
        "\n",
        "        foreach (var loc in splitData.splits.train)\n",
        "        {\n",
        "            var row = dataTable.NewRow();\n",
        "            row[\"location\"] = loc;\n",
        "            dataTable.Rows.Add(row);\n",
        "        }\n",
        "\n",
        "        await bulkCpy.WriteToServerAsync(dataTable);\n",
        "    }\n",
        "\n",
        "    using (var bulkCpy = new SqlBulkCopy(sqlConn))\n",
        "    {\n",
        "        bulkCpy.DestinationTableName = \"val\";\n",
        "\n",
        "        var dataTable = new DataTable();\n",
        "        dataTable.Columns.Add(\"location\", typeof(string));\n",
        "\n",
        "        foreach (var loc in splitData.splits.val)\n",
        "        {\n",
        "            var row = dataTable.NewRow();\n",
        "            row[\"location\"] = loc;\n",
        "            dataTable.Rows.Add(row);\n",
        "        }\n",
        "\n",
        "        await bulkCpy.WriteToServerAsync(dataTable);\n",
        "    }\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 214,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:54.09693Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:56.2006026Z",
              "execution_finish_time": "2023-01-31T13:03:56.389574Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 214, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 214,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "InitStorageAndDb();\n",
        "await CreateTablesAsync();\n",
        "\n",
        "//season files\n",
        "var seasonFiles = new List<string>()\n",
        "{\n",
        "    \"SnapshotSerengetiS01.json\",\n",
        "    \"SnapshotSerengetiS02.json\",\n",
        "    \"SnapshotSerengetiS03.json\",\n",
        "    \"SnapshotSerengetiS04.json\",\n",
        "    \"SnapshotSerengetiS05.json\",\n",
        "    \"SnapshotSerengetiS06.json\",\n",
        "    \"SnapshotSerengetiS07.json\",\n",
        "    \"SnapshotSerengetiS08.json\",\n",
        "    \"SnapshotSerengetiS09.json\",\n",
        "    \"SnapshotSerengetiS10.json\",\n",
        "    \"SnapshotSerengetiS11.json\"\n",
        "};\n",
        "\n",
        "foreach (var file in seasonFiles)\n",
        "{\n",
        "    var blob = blobDirectory.GetBlockBlobReference(file);\n",
        "    var serengetiData=await ReadJsonFile<SerengetiData>(blob);\n",
        "\n",
        "    if(seasonFiles.IndexOf(file) == 0)\n",
        "        await BulkInsertCategories(serengetiData.Categories);\n",
        "\n",
        "    await BulkInsertImages(serengetiData.Images);\n",
        "    await BulkInsertAnnotations(serengetiData.Annotations);\n",
        "}\n",
        "\n",
        "var blob = blobDirectory.GetBlockBlobReference(\"SnapshotSerengetiSplits_v0.json\");\n",
        "var splitData = await ReadJsonFile<dynamic>(blob);\n",
        "\n",
        "await BulkInsertSplits(splitData);"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "DefaultPool",
              "session_id": "28",
              "statement_id": 215,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-31T13:03:54.196962Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-31T13:03:56.5052426Z",
              "execution_finish_time": "2023-01-31T13:09:00.2873841Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(DefaultPool, 28, 215, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table images created successfully.\nTable categories created successfully.\nTable annotations created successfully.\nTable train created successfully.\nTable val created successfully.\n"
          ]
        }
      ],
      "execution_count": 215,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "csharp"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}